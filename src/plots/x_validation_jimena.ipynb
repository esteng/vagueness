{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation exercise \n",
    "\n",
    "This is a little exercise to look at some basic ML and statistics concepts while dealing with the data that we collected ourselves! I think the best way to understand these concepts is by dealing with actual data, so here goes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem\n",
    "We've collected our data from Mechanical Turk and now we want to analyze it. The first step with this should always be plotting the data. Luckily, the plotting code was pretty much done, and we don't have much left to do. For the sake of time/not being redundant, I'll just point to the existing plotting code, which is in `plot_turk_results.ipynb`. The result of plotting this data looks like this: \n",
    "\n",
    "![data plotted](scores_version_1.pdf)\n",
    "\n",
    "What we see is that the data is distributed in a sort of s-shaped curve, which shows that our hypothesis about vague predicates is confirmed by the data: human annotators don't agree about vague predicates, and there are examples in the middle which are hard for them to classify. But here's the problem: we only have 4 pages of content for our paper to convince our reader that this trend holds across all our predicates. Of course, we could include a plot for each predicate, but we have 7 predicates across 2 datasets, so that's 14 plots, which is a lot of space. It's probably better to just show a couple illustrative plots, and then have some kind of quantitative measure that tells us the other plots also fall into this pattern. \n",
    "\n",
    "So how do quantify the \"s-ness\" of the data for each predicate? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve fitting \n",
    "We can rephrase this problem into the langauge of statistics to quantify our \"s-ness\". Let's back off to a simpler case. Consider the following data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x113a17510>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "\n",
    "xs = np.arange(0, 30, 1)\n",
    "ys = 1/2 * (xs + np.random.normal(0, 1, len(xs))) - 1 \n",
    "\n",
    "plt.ylim(0,30)\n",
    "plt.xlim(0,30)\n",
    "\n",
    "plt.plot(xs, ys, \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the data follows a linear trend, with some noise that causes it to jiggle off of the line of best fit. If you look at the code, that's exactly how I generated the data. So you could say that we have a *hypothesis class* of functions that we think generated this data (a linear equation with some Gaussian noise) and what we need to do to test that hypothesis is find the best fit in our hypothesis class, and apply it to the data. \n",
    "\n",
    "The way we fit the line is by adjusting the parameters until it best fits our data. Sometimes we can do that in closed form: for a line with equation $y = mx + b$, given $x$ and $y$ we can solve for the parameters $m$ and $b$ to get their optimal values in one step. For more complicated functions, we'll approximate that process with iterative methods like gradient descent. \n",
    "\n",
    "**Exercise** Eyeball what you think is the best-fit line and plot it. Then get an estimate by using [scipy.linregress](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.linregress.html) and plot it as well\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 1 here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In real life, we don't get to know how the data was generated, but we can still have a hypothesis class of functions that we think approximate our data. That's why plotting it is an important first step. We can then test our hypothesis by fitting our function to the data as best we can, and measuring the error of that best fit. So, for example, with the line data, we could fit a line, a polynomial function, a sinusoidal function, a normal distribution, etc. etc. and then compare them. Broadly, if one does better than another, we can say it better accounts for the data. \n",
    "\n",
    "So for our S-shaped data, we're looking for a function that's S-shaped: for example, the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1133fee50>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAASfklEQVR4nO3df2xdZ33H8ffXcQ0SdBA5RpQmc2otILIfEo3VmcG0ai0jraZkY4OlK9oYhIiNTKCxTa06dVX5Y+oQ/IEW6LKCGCijFDaYxYLCfgQhTbiLDW0hLWHG1GsyRo3nlU0IEsvf/XFvqotz7Xsc3x/2k/dLsnLPOc+556vnXn9y/JxfkZlIkja/vl4XIElqDwNdkgphoEtSIQx0SSqEgS5Jhejv1Ya3bduWO3fu7NXmJWlTmpqa+m5mDjVb1rNA37lzJ5OTk73avCRtShExu9Iyh1wkqRAGuiQVwkCXpEIY6JJUCANdkgrRMtAj4sMR8XREfG2F5RER74+I6Yh4LCKub3+ZkqRWquyhfwTYu8ryW4Bd9Z9DwAfXX5YkdcbU7AJHTk4zNbuwKddfTcvz0DPzixGxc5Um+4GPZu0+vBMR8cKIuCYzv92uIiXpoqnZBSZm5hkbGWTP8NY1r3v7AxOcX1xioL+PYwfH1vQevV6/lXaMoV8LPNUwfbY+7xIRcSgiJiNicm5urg2blrTZrGcP9WIgvvfzZ7j9gYk1v8fEzDznF5dYSriwuMTEzPymWr+Vrh4UzcyjmTmamaNDQ02vXJVUsF4H8tjIIAP9fWwJuKq/j7GRwU21fivtuPT/HLCjYXp7fZ6kAq1nyKNZIK/lPS4G4oXFpcsKxD3DWzl2cOyy6+/1+q20I9DHgcMR8SDws8Azjp9LZVrvGHCvA/nie6wnSHu9/mpaBnpEfBy4EdgWEWeBPwWuAsjM+4HjwK3ANPB94Hc6UqmknlvvHvZGCOSSVTnL5bYWyxN4e9sqkrRhrXcPGwzkTurZ7XMlbT6dHgPW+hjoktbEPeyNy3u5SFeYTl6pqN5yD126gnT6SkX1lnvo0hWk01cqqrcMdOkK0ukrFdVbDrlIVxDPUimbgS5dYTxLpVwOuUhSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLm4x3S9RKvFJU2kS8W6JW4x66tIl4t0StxkCXNhHvlqjVOOQibSLeLVGrMdClTca7JWolDrlIUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhKgV6ROyNiDMRMR0RdzRZ/uMRcTIivhIRj0XEre0vVZK0mpaBHhFbgCPALcBu4LaI2L2s2Z8AD2XmK4ADwAfaXagkaXVV9tBvAKYzcyYzzwMPAvuXtUngx+qvXwD8Z/tKlCRVUSXQrwWeapg+W5/X6B7gjRFxFjgO/H6zN4qIQxExGRGTc3Nzl1GuJGkl7TooehvwkczcDtwKfCwiLnnvzDyamaOZOTo0NNSmTUuSoFqgnwN2NExvr89r9BbgIYDM/BLwXGBbOwqUJFVTJdBPAbsi4rqIGKB20HN8WZv/AG4CiIiXUwt0x1QkqYtaBnpmLgKHgRPAE9TOZjkdEfdGxL56s3cBb42IR4GPA2/KzOxU0ZKkS1V6YlFmHqd2sLNx3t0Nrx8HXtXe0iRJa+GVopJUCANdkgphoEtSIQx0SSqEgS5JhTDQpS6bml3gyMlppmYXel2KClPptEVJ7TE1u8DtD0xwfnGJgf4+jh0cY8/w1l6XpUK4hy510cTMPOcXl1hKuLC4xMTMfK9LUkEMdKmLxkYGGejvY0vAVf19jI0M9rokFcQhF6mL9gxv5djBMSZm5hkbGXS4RW1loEtdtmd4q0GujnDIRZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSpEpUCPiL0RcSYipiPijhXavCEiHo+I0xHxN+0tU5LUSsuHREfEFuAI8BrgLHAqIsYz8/GGNruAO4FXZeZCRLyoUwVLkpqrsod+AzCdmTOZeR54ENi/rM1bgSOZuQCQmU+3t0xJUitVAv1a4KmG6bP1eY1eCrw0Iv41IiYiYm+zN4qIQxExGRGTc3Nzl1exJKmpdh0U7Qd2ATcCtwF/FREvXN4oM49m5mhmjg4NDbVp05IkqBbo54AdDdPb6/ManQXGM/NCZn4L+Aa1gJckdUmVQD8F7IqI6yJiADgAjC9r8xlqe+dExDZqQzAz7StTktRKy0DPzEXgMHACeAJ4KDNPR8S9EbGv3uwEMB8RjwMngT/KzPlOFS1JulRkZk82PDo6mpOTkz3ZtiRtVhExlZmjzZZ5pagkFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS2swNbvAkZPTTM0u9LoU6RItHxItqWZqdoHbH5jg/OISA/19HDs4xp7hrb0uS3qWe+hSRRMz85xfXGIp4cLiEhMz3vJfG4uBLlU0NjLIQH8fWwKu6u9jbGSw1yVJP8IhF6miPcNbOXZwjImZecZGBh1u0YZjoEtrsGd4q0GuDcshF0kqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEJUCvSI2BsRZyJiOiLuWKXdr0VERsRo+0qUJFXRMtAjYgtwBLgF2A3cFhG7m7S7GngH8HC7i5QktVZlD/0GYDozZzLzPPAgsL9Ju3cD9wE/aGN9kqSKqgT6tcBTDdNn6/OeFRHXAzsy8x9We6OIOBQRkxExOTc3t+ZiJUkrW/dB0YjoA94HvKtV28w8mpmjmTk6NDS03k1LkhpUCfRzwI6G6e31eRddDfwU8IWIeBIYA8Y9MCpJ3VUl0E8BuyLiuogYAA4A4xcXZuYzmbktM3dm5k5gAtiXmZMdqViS1FTLQM/MReAwcAJ4AngoM09HxL0Rsa/TBUqSqumv0igzjwPHl827e4W2N66/LEnSWnmlqCQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjouqJMzS5w5OQ0U7MLvS5FartKzxSVSjA1u8DtD0xwfnGJgf4+jh0cY8/w1l6XJbWNe+i6YkzMzHN+cYmlhAuLS0zMzPe6JKmtDHRdMcZGBhno72NLwFX9fYyNDPa6JKmtHHLRFWPP8FaOHRxjYmaesZFBh1tUHANdV5Q9w1sNchXLIRdJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUiEqBHhF7I+JMRExHxB1Nlv9BRDweEY9FxD9HxHD7S5UkraZloEfEFuAIcAuwG7gtInYva/YVYDQzfwb4FPDn7S5UkrS6KnvoNwDTmTmTmeeBB4H9jQ0y82Rmfr8+OQFsb2+ZkqRWqgT6tcBTDdNn6/NW8hbgc80WRMShiJiMiMm5ubnqVUqSWmrrQdGIeCMwCryn2fLMPJqZo5k5OjQ01M5NS9IVr8q9XM4BOxqmt9fn/YiIuBm4C/iFzPxhe8qTJFVVZQ/9FLArIq6LiAHgADDe2CAiXgH8JbAvM59uf5mSpFZaBnpmLgKHgRPAE8BDmXk6Iu6NiH31Zu8Bng98MiIeiYjxFd5OktQhlW6fm5nHgePL5t3d8PrmNtclSVojrxSVpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJA16YyNbvAkZPTTM0u9LoUacOpdKWotBFMzS5w+wMTnF9cYqC/j2MHx9gzvLXXZUkbhnvo2jQmZuY5v7jEUsKFxSUmZuZ7XZK0oRjo2jTGRgYZ6O9jS8BV/X2MjQz2uiRpQ3HIRZvGnuGtHDs4xsTMPGMjgw63SMsY6NpU9gxvNcilFTjkIkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQ1VXe/lbqHC/9V9d4+1ups9xDV9d4+1upswx0dY23v5U6yyEXdY23v5U6y0DXmkzNLqwrkL39rdQ5Broq86CmtLE5hq7KPKgpbWyVAj0i9kbEmYiYjog7mix/TkR8or784YjY2fZKBaz/PO71rO9BTWljaznkEhFbgCPAa4CzwKmIGM/MxxuavQVYyMyfiIgDwH3Ab3Si4PWO4W7m9dc75LHe9T2oKW1sVcbQbwCmM3MGICIeBPYDjYG+H7in/vpTwF9ERGRmtrHWngdar9dvNuTRzfXBg5rSRlZlyOVa4KmG6bP1eU3bZOYi8Axwyd/jEXEoIiYjYnJubm7Nxa53DHezr7/eIQ+HTKSydfUsl8w8ChwFGB0dXfPe+8VAurC4tK5A26zrr3fIwyETqWzRalQkIl4J3JOZr61P3wmQmX/W0OZEvc2XIqIf+C9gaLUhl9HR0ZycnFxzwZt5DLwd60u6skXEVGaONl1WIdD7gW8ANwHngFPAb2bm6YY2bwd+OjPfVj8o+rrMfMNq73u5gS5JV7LVAr3lkEtmLkbEYeAEsAX4cGaejoh7gcnMHAc+BHwsIqaB/wYOtK98SVIVlcbQM/M4cHzZvLsbXv8AeH17S5MkrYVXikpSIQx0SSqEgS5JhTDQJakQLU9b7NiGI+aA2ctcfRvw3TaW027Wtz7Wt34bvUbru3zDmTnUbEHPAn09ImJypfMwNwLrWx/rW7+NXqP1dYZDLpJUCANdkgqxWQP9aK8LaMH61sf61m+j12h9HbApx9AlSZfarHvokqRlDHRJKsSGDfSIeH1EnI6IpYgYXbbszvoDqc9ExGtXWP+6+gOrp+sPsB7oYK2fiIhH6j9PRsQjK7R7MiK+Wm/XtXsHR8Q9EXGuocZbV2i36sPAO1jfeyLi6xHxWER8OiJeuEK7rvbfRn44ekTsiIiTEfF4/ffkHU3a3BgRzzR87nc3e68O1rjq5xU176/332MRcX0Xa3tZQ788EhHfi4h3LmvT0/67LJm5IX+AlwMvA74AjDbM3w08CjwHuA74JrClyfoPAQfqr+8HfrdLdb8XuHuFZU8C23rQl/cAf9iizZZ6X44AA/U+3t2l+n4J6K+/vg+4r9f9V6U/gN8D7q+/PgB8oouf6TXA9fXXV1N7ZsHy+m4EPtvt71vVzwu4FfgcEMAY8HCP6txC7aE8wxup/y7nZ8PuoWfmE5l5psmi/cCDmfnDzPwWME3tQdbPiogAfpHaA6sB/hr4lQ6W27jdNwAf7/S2OuDZh4Fn5nng4sPAOy4zP5+1Z9ECTADbu7HdFqr0x35q3y2ofdduqn8HOi4zv52ZX66//l/gCS591u9Gtx/4aNZMAC+MiGt6UMdNwDcz83KvXN8wNmygr6LKQ6sHgf9pCIlmbTrh54HvZOa/r7A8gc9HxFREHOpCPY0O1/+s/XBENHv2XZV+7YY3U9tra6ab/de2h6N3Wn2o5xXAw00WvzIiHo2Iz0XET3a3spaf10b5zh1g5Z2wXvbfmnX1IdHLRcQ/AS9usuiuzPz7btezmoq13sbqe+evzsxzEfEi4B8j4uuZ+cVO1wd8EHg3tV+wd1MbFnpzO7ZbVZX+i4i7gEXg2Apv07H+26wi4vnA3wLvzMzvLVv8ZWrDCP9XP27yGWBXF8vb8J9X/djaPuDOJot73X9r1tNAz8ybL2O1c8COhunt9XmN5qn9+dZf33Nq1mZNWtUatWevvg7Ys8p7nKv/+3REfJran/Vt+YJX7cuI+Cvgs00WVenXy1ah/94E/DJwU9YHMJu8R8f6r4kq/XGxzdn65/8Cat+9roiIq6iF+bHM/LvlyxsDPjOPR8QHImJbZnblplMVPq+OfucqugX4cmZ+Z/mCXvff5diMQy7jwIH6GQbXUfsf898aG9QD4STw6/VZvw10eo//ZuDrmXm22cKIeF5EXH3xNbUDgV/rcE0Xt904LvmrK2z3FLAramcHDVD7M3S8S/XtBf4Y2JeZ31+hTbf7r0p/jFP7bkHtu/YvK/1n1G71sfoPAU9k5vtWaPPii2P6EXEDtd/3rvyHU/HzGgd+q362yxjwTGZ+uxv1NVjxr+pe9t9l6/VR2ZV+qAXPWeCHwHeAEw3L7qJ2BsIZ4JaG+ceBl9Rfj1AL+mngk8BzOlzvR4C3LZv3EuB4Qz2P1n9OUxtq6FZffgz4KvAYtV+ia5bXV5++ldrZEt/scn3T1MZSH6n/3L+8vl70X7P+AO6l9h8PwHPr363p+ndtpIt99mpqQ2iPNfTbrcDbLn4PgcP1vnqU2sHmn+tifU0/r2X1BXCk3r9fpeFsti7V+DxqAf2Chnkbov8u98dL/yWpEJtxyEWS1ISBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgrx/1ioHuco0FEfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x, x0, k):\n",
    "    return 1.0 / (1.0 + np.exp(-k * (x-x0)))\n",
    "\n",
    "\n",
    "xs = np.arange(-10, 10, 1)\n",
    "ys = [sigmoid(x, 0, 1) for x in xs] \n",
    "plt.plot(xs, ys, \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have parameters `x0` which controls the shift (left and right) and `k` which controls the vertical dimension. **Exercise** Try playing with different values on these to see what varying them does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 2: play with sigmoid here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with lines, we can fit a sigmoid curve to our data. It's a worthwhile exercise to figure out how to do this from scratch, but it requires a bit more linear algebra. For background info, you can read up on [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression). \n",
    "We'll let someone else handle the curve fitting, namely `scipy`, which has almost all of the stats and most ML things you can think of bundled together in a nice, well-implemented package. Combined with `numpy`, knowing `scipy` is well probably sufficient to do 90% of all data science work. Here's a wrapper function for fitting sigmoid curves from our data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sigmoid(data):\n",
    "    xs = np.arange(len(data.keys()))\n",
    "    ys = [np.mean([line['p_true']  for line in data[key] ] ) for key in data.keys() ]\n",
    "    ys = np.array(ys)/100\n",
    "    popt, pcov = curve_fit(sigmoid, xs, ys, p0= [20, 0.1], method='dogbox')\n",
    "    pred_ys = np.array([sigmoid(x, popt[0], popt[1]) for x in xs])\n",
    "    # use mean squared error\n",
    "    goodness_of_fit = np.sqrt(np.sum((pred_ys - ys)**2) / len(pred_ys))\n",
    "    return goodness_of_fit, popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll break this down line by line:\n",
    "\n",
    "```xs = np.arange(len(data.keys()))``` defines the points along the x axis, in this case just 0, 1, 2, ...\n",
    "\n",
    "```ys = [np.mean([line['p_true']  for line in data[key] ] ) for key in data.keys() ]``` sets the y values to the average slide-bar value assigned by each annotator (there are 10 of these). \n",
    "\n",
    "```ys = np.array(ys)/100``` **Exercise** do some reading about the sigmoid function so see why this line is necessary \n",
    "\n",
    "```popt, pcov = curve_fit(sigmoid, xs, ys, p0= [20, 0.1], method='dogbox')``` calls scipy's function, **exercise** read the docs for `curve_fit` to see what the parameters here are and what the function returns.\n",
    "\n",
    "```pred_ys = np.array([sigmoid(x, popt[0], popt[1]) for x in xs])``` based on our parameter estimates from scipy, we can get the predicted values for each `x` point. \n",
    "\n",
    "``` goodness_of_fit = np.sqrt(np.sum((pred_ys - ys)**2) / len(pred_ys))``` measures the root mean squared error, which tells us how far off the predicted values were from the real values. This is a way to quantify the error of our best fit model. If you want more info on it, you can check [here](https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3 explanation here: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
